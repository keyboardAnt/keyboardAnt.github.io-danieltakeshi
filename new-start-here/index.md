---
title: New? Start Here
layout: page
---

You can see the one-paragraph description of the blog in the footers, repeated
here for convenience:

*This is my blog, where I have written over 225 articles on a variety of topics,
most of which are about one of two major themes. The first is computer science,
which is my area of specialty as a Ph.D. student at UC Berkeley. The second can
be broadly categorized as "deafness," which relates to my experience and
knowledge of being deaf.*

The easiest way to find something that you'll be interested in is to [look at
the archives][10] and browse the titles, which (I hope) are descriptive. Using
the built-in Google site search there would also be useful.

If you're interested in knowing more about the classes at Berkeley, I write
reviews on all the ones I have taken. Here they are:

- [CS 267, Applications of Parallel Computing][40]
- [CS 280, Computer Vision][39]
- [CS 281A, Statistical Learning Theory][38]
- [CS 287, Advanced Robotics][1]
- [CS 288, Natural Language Processing][37]
- [CS 294-112, Deep Reinforcement Learning][2]
- [CS 294-115, Algorithmic Human-Robot Interaction][29]
- [EE 227BT, Convex Optimization][3]
- [EE 227C, Convex Optimization and Approximation][4]
- [STAT 210A, Theoretical Statistics][28]

When I was preparing for the AI prelims at Berkeley, I wrote a lot about AI
topics. I also wrote a "transcript" of my prelims.

- [My Prelims][9] *[Transcript]*
- [Markov Decision Processes and Reinforcement Learning][5]
- [Perceptrons, SVMs, and Kernel Methods][6]
- [Notes on Exact Inference in Graphical Models][7]
- [The Least Mean Squares Algorithm][8]
- [Expectation-Maximization][35]
- [Hidden Markov Models and Particle Filtering][36]

I also write a lot about other technical areas, and am attempting to write up
more about my thoughts on various technical research papers. Here are a few:

- [Notes on the Generalized Advantage Estimation Paper][42]
- [Going Deeper Into Reinforcement Learning: Fundamentals of Policy Gradients][33]
- [Going Deeper Into Reinforcement Learning: Understanding Deep-Q-Networks][30]
- [Going Deeper Into Reinforcement Learning: Understanding Q-Learning and Linear Function Approximation][34]
- [Understanding Higher Order Local Gradient Computation for Backpropagation in Deep Neural Networks][32]
- [Understanding Generative Adversarial Networks][41]
- [Some Recent Results on Minibatch Markov Chain Monte Carlo Methods][25]
- [Independent Component Analysis --- A Gentle Introduction][17]
- [Ten Things Python Programmers Should Know][14]

If you are interested in knowing about what it's like being deaf, then there are
a *lot* of options.  Here are a few that might be informative:

- [The Obligatory "Can I Lip Read?" Question][19]
- [The BVLC (BAIR) Retreat: Disaster Averted!][18]
- [Advocate for Yourself][13]
- [After a Few Weeks of CART, Why do I Feel Dissatisfied?][16]
- [The Problem with Seminars][15]
- [My Pre-College Education as a Deaf Mainstreamed Student][22]
- [New Closed-Captioning Glasses][23]
- [Hearing Aids: How They Help and How They Fall Short in Group Situations][11]
- [Technical Term Dilemma][21]
- [Why Computer Science is a Good Major for Deaf Students][12]

Finally, I write sometimes about the books I read, such as in the following:

- [All the Books I Read in 2016, Plus My Thoughts [Long]][26]
- [My Three Favorite Books I Read in 2015][20]
- [The Master Algorithm: How the Quest for the Ultimate Learning Machine Will
  Remake Our World][27]

[1]:https://danieltakeshi.github.io/2015-12-21-review-of-advanced-robotics-cs-287-at-berkeley/
[2]:https://danieltakeshi.github.io/2015-12-17-review-of-deep-reinforcement-learning-cs-294-112-at-berkeley/
[3]:https://danieltakeshi.github.io/2015-12-22-review-of-convex-optimization-ee-227bt-at-berkeley/
[4]:https://danieltakeshi.github.io/2016-05-21-review-of-convex-optimization-and-approximation-ee-227c-at-berkeley/
[5]:https://danieltakeshi.github.io/2015-08-02-markov-decision-processes-and-reinforcement-learning/
[6]:https://danieltakeshi.github.io/2015-08-08-perceptrons-svms-and-kernel-methods.md/
[7]:https://danieltakeshi.github.io/2015-07-12-notes-on-exact-inference-in-graphical-models/
[8]:https://danieltakeshi.github.io/2015-07-29-the-least-mean-squares-algorithm/
[9]:https://danieltakeshi.github.io/2015-09-01-my-prelims/
[10]:https://danieltakeshi.github.io/archive.html
[11]:https://danieltakeshi.github.io/2012/08/06/hearing-aids-how-they-help-and-how-they-fall-short-in-group-situations/
[12]:https://danieltakeshi.github.io/2013/02/06/why-computer-science-is-a-good-major-for-deaf-students/
[13]:https://danieltakeshi.github.io/2015-06-20-advocate-for-yourself/
[14]:https://danieltakeshi.github.io/2013/07/05/ten-things-python-programmers-should-know/
[15]:https://danieltakeshi.github.io/2013/11/10/the-problem-with-seminars/
[16]:https://danieltakeshi.github.io/2014/10/05/after-a-few-weeks-of-cart-why-do-i-feel-dissatisfied/
[17]:https://danieltakeshi.github.io/2015/01/03/independent-component-analysis-a-gentle-introduction/
[18]:https://danieltakeshi.github.io/2016-04-16-the-bvlc-bair-retreat-disaster-averted/
[19]:https://danieltakeshi.github.io/2016-05-24-the-obligatory-can-i-lip-read-question/
[20]:https://danieltakeshi.github.io/2015-12-28-my-three-favorite-books-i-read-in-2015/
[21]:https://danieltakeshi.github.io/2012/02/04/technical-term-dilemma/
[22]:https://danieltakeshi.github.io/2013/08/08/my-pre-college-education-as-a-deaf-mainstreamed-student/
[23]:https://danieltakeshi.github.io/2013/06/28/new-closed-captioning-glasses/
[24]:https://danieltakeshi.github.io/2013/07/12/its-time-to-ditch-powerpoint-and-word-in-favor-of-latex/
[25]:https://danieltakeshi.github.io/2016-06-19-some-recent-results-on-minibatch-markov-chain-monte-carlo-methods/
[26]:https://danieltakeshi.github.io/2016/12/31/all-the-books-i-read-in-2016-plus-my-thoughts-long
[27]:https://danieltakeshi.github.io/2016-05-31-the-master-algorithm-how-the-quest-for-the-ultimate-learning-machine-will-remake-our-world/
[28]:https://danieltakeshi.github.io/2016/12/20/review-of-theoretical-statistics-stat-210a-at-berkeley/
[29]:https://danieltakeshi.github.io/2016/12/20/review-of-algorithmic-human-robot-interaction-cs-294-115-at-berkeley/
[30]:https://danieltakeshi.github.io/2016/12/01/going-deeper-into-reinforcement-learning-understanding-dqn/
[31]:https://danieltakeshi.github.io/2016/12/30/five-years-of-blogging/
[32]:https://danieltakeshi.github.io/2017/01/21/understanding-higher-order-local-gradient-computation-for-backpropagation-in-deep-neural-networks/
[33]:https://danieltakeshi.github.io/2017/03/28/going-deeper-into-reinforcement-learning-fundamentals-of-policy-gradients/
[34]:https://danieltakeshi.github.io/2016/10/31/going-deeper-into-reinforcement-learning-understanding-q-learning-and-linear-function-approximation/
[35]:https://danieltakeshi.github.io/2015-07-25-hidden-markov-models-and-particle-filtering/
[36]:https://danieltakeshi.github.io/2015-07-18-expectation-maximization/
[37]:https://danieltakeshi.github.io/2015/02/14/review-of-natural-language-processing-cs-288-at-berkeley/
[38]:https://danieltakeshi.github.io/2014/12/30/review-of-statistical-learning-theory-cs-281a-at-berkeley/
[39]:https://danieltakeshi.github.io/2015-05-31-review-computer-vision-berkeley/
[40]:https://danieltakeshi.github.io/2016-05-27-review-of-applications-of-parallel-computing-cs-267-at-berkeley/
[41]:https://danieltakeshi.github.io/2017/03/05/understanding-generative-adversarial-networks/
[42]:https://danieltakeshi.github.io/2017/04/02/notes-on-the-generalized-advantage-estimation-paper/
